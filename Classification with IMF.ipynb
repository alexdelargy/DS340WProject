{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scripts related to venv\n",
    "### Open a terminal\n",
    "- .venv\\Scripts\\activate\n",
    "- py -m pip install --upgrade pip\n",
    "- py -m pip install requests\n",
    "- py -m pip freeze > requirements.txt\n",
    "- py -m pip install -r requirements.txt\n",
    "\n",
    "# AWS Article\n",
    "- https://induraj2020.medium.com/how-to-access-the-s3-bucket-using-python-ecdbe5ebc45f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Classification\n",
    "In this notebook I tried to learn the basic concepts of neural networks and use it to classify the music files in dataset. Majorly this notebook can be divided into 3 parts:\n",
    "\n",
    "   1) Using ANN \n",
    "\n",
    "   2) Tackling overfitting with ANN\n",
    "\n",
    "   3) Using CNN\n",
    "\n",
    "\n",
    "Also to read the dataset I have used librosa library which only read files <1Mb and one file is greater than the size giving error due to which I have ignored it. The dataset contains the following genres, the keys being the prediction targets\n",
    "    \n",
    "    0: \"disco\",\n",
    "    1: \"metal\",\n",
    "    2: \"reggae\",\n",
    "    3: \"blues\",\n",
    "    4: \"rock\",\n",
    "    5: \"classical\",\n",
    "    6: \"jazz\",\n",
    "    7: \"hiphop\",\n",
    "    8: \"country\",\n",
    "    9: \"pop\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "01a50213-fe5d-431b-9ade-28c438b3bceb",
    "_uuid": "f32a1031-9332-42b6-8335-dee2b86310a3",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mboto3\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "from PIL import Image\n",
    "import boto3\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import numpy as np\n",
    "import warnings \n",
    "import requests\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(bucket_name, image_key, target_size=(128, 128)):\n",
    "    s3 = boto3.client('s3')\n",
    "    image_data = s3.get_object(Bucket=bucket_name, Key=image_key)['Body'].read()\n",
    "\n",
    "    image = Image.open(io.BytesIO(image_data)).convert('RGB')\n",
    "\n",
    "    image = image.resize(target_size)\n",
    "\n",
    "    return np.array(image).flatten() / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(bucket_name, dataset_path, target_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_mapping = {}\n",
    "    s3 = boto3.client('s3')\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "\n",
    "    for i, page in enumerate(paginator.paginate(Bucket=bucket_name, Prefix=dataset_path)):\n",
    "        if 'Contents' not in page:\n",
    "            continue\n",
    "        \n",
    "        for obj in page['Contents']:\n",
    "            image_key = obj['Key']\n",
    "            if image_key.endswith(\".png\"):\n",
    "                genre_label = image_key.split('/')[-2]\n",
    "\n",
    "                if genre_label not in label_mapping:\n",
    "                    label_mapping[genre_label] = len(label_mapping)\n",
    "\n",
    "                image_array = load_image(bucket_name, image_key, target_size)\n",
    "\n",
    "                images.append(image_array)\n",
    "                labels.append(label_mapping[genre_label])\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_images(bucket_name='flights12345', dataset_path=r\"Data/images_original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training/validation/testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "train_size = int(0.7 * 999)\n",
    "test_size = int(0.15 * 999)\n",
    "validation_size = int(0.15 * 999)\n",
    "\n",
    "groups = np.array([0] * train_size + [1] * test_size + [2] * validation_size)\n",
    "np.random.shuffle(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, validation_images, test_images = [], [], []\n",
    "train_labels, validation_labels, test_labels = np.array([]), np.array([]), np.array([])\n",
    "\n",
    "for i, group in enumerate(groups):\n",
    "    if group == 0:\n",
    "        train_images.append(images[i])\n",
    "        train_labels = np.append(train_labels, labels[i])\n",
    "    elif group == 1:\n",
    "        validation_images.append(images[i])\n",
    "        validation_labels = np.append(validation_labels, labels[i])\n",
    "    else:\n",
    "        test_images.append(images[i])\n",
    "        test_labels = np.append(test_labels, labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, validation_images, test_images = np.array(train_images), np.array(validation_images), np.array(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create IMFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import CubicSpline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_extrema(signal):\n",
    "    maxima = []\n",
    "    minima = []\n",
    "    \n",
    "    for i in range(1, len(signal) - 1):\n",
    "        if signal[i-1] < signal[i] > signal[i+1]:\n",
    "            maxima.append(i)\n",
    "        elif signal[i-1] > signal[i] < signal[i+1]:\n",
    "            minima.append(i)\n",
    "            \n",
    "    return np.array(maxima), np.array(minima)\n",
    "\n",
    "def compute_envelope(t, signal, extrema):\n",
    "    if len(extrema) > 0:\n",
    "        if extrema[0] > 0:\n",
    "            extrema = np.r_[0, extrema]\n",
    "        if extrema[-1] < len(signal) - 1:\n",
    "            extrema = np.r_[extrema, len(signal) - 1]\n",
    "            \n",
    "        return CubicSpline(extrema, signal[extrema])(t)\n",
    "    return np.zeros_like(signal)\n",
    "\n",
    "def IMFextraction(signal, max_iterations=10, tolerance=0.1):\n",
    "    s = signal.copy()\n",
    "    l = np.arange(len(signal))\n",
    "    \n",
    "    for _ in range(max_iterations):\n",
    "        maxima, minima = find_extrema(s)\n",
    "        \n",
    "        if len(maxima) + len(minima) < 3:\n",
    "            break\n",
    "            \n",
    "        upper_envelope = compute_envelope(l, s, maxima)\n",
    "        lower_envelope = compute_envelope(l, s, minima)\n",
    "        mean_envelope = (upper_envelope + lower_envelope) / 2\n",
    "        \n",
    "        s_previous = s.copy()\n",
    "        s = s - mean_envelope\n",
    "        \n",
    "        if np.all(np.abs((s_previous - s) / (s_previous + np.finfo(float).eps)) < tolerance):\n",
    "            break\n",
    "            \n",
    "    return s\n",
    "\n",
    "def decompose_to_imfs(signal, extract_imf, num_imfs=3):\n",
    "    imfs = []\n",
    "    residual = signal.copy()\n",
    "    \n",
    "    for _ in range(num_imfs):\n",
    "        imf = extract_imf(residual)\n",
    "        imfs.append(imf)\n",
    "        residual = residual - imf\n",
    "        \n",
    "    return np.array(imfs)\n",
    "\n",
    "def process_images_imf(image_set, num_imfs=3, reshape_size=(128, 128, 3)):\n",
    "    processed_images = []\n",
    "    \n",
    "    for img in image_set:\n",
    "        img_reshaped = img.reshape(reshape_size)\n",
    "        \n",
    "        channel_imfs = []\n",
    "        for channel in range(3):\n",
    "            channel_data = img_reshaped[:, :, channel].flatten()\n",
    "            imfs = decompose_to_imfs(channel_data, num_imfs)\n",
    "            channel_imfs.append(imfs)\n",
    "            \n",
    "        processed_images.append(channel_imfs)\n",
    "    \n",
    "    return np.array(processed_images)\n",
    "\n",
    "def visualize_images_imf(original_image, imfs, genre_mapping, label, num_imfs_to_show=3):\n",
    "    plt.figure(figsize=(15, 5 * (num_imfs_to_show + 1)))\n",
    "    \n",
    "    genre_names = {v: k for k, v in genre_mapping.items()}\n",
    "    genre = genre_names.get(label, \"Unknown\")\n",
    "    \n",
    "    plt.subplot(num_imfs_to_show + 1, 1, 1)\n",
    "    plt.imshow(original_image.reshape(128, 128, 3))\n",
    "    plt.title(f'Original Image - Genre: {genre}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    for i in range(num_imfs_to_show):\n",
    "        plt.subplot(num_imfs_to_show + 1, 1, i + 2)\n",
    "        \n",
    "        imf_image = np.zeros((128, 128, 3))\n",
    "        for c in range(3):\n",
    "            imf_image[:, :, c] = imfs[c][i].reshape(128, 128)\n",
    "            \n",
    "        plt.imshow(imf_image + 0.5)\n",
    "        plt.title(f'IMF {i+1}')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "genre_mapping = {\n",
    "    \"disco\": 0,\n",
    "    \"metal\": 1,\n",
    "    \"reggae\": 2,\n",
    "    \"blues\": 3,\n",
    "    \"rock\": 4,\n",
    "    \"classical\": 5,\n",
    "    \"jazz\": 6,\n",
    "    \"hiphop\": 7,\n",
    "    \"country\": 8,\n",
    "    \"pop\": 9\n",
    "}\n",
    "\n",
    "def process_and_visualize(train_images, train_labels, num_samples=3, num_imfs=3):\n",
    "    indices = np.random.choice(len(train_images), num_samples, replace=False)\n",
    "    \n",
    "    for idx in indices:\n",
    "        image = train_images[idx]\n",
    "        label = train_labels[idx]\n",
    "        \n",
    "        imfs = process_images_imf(image.reshape(1, -1), num_imfs)[0]\n",
    "        \n",
    "        visualize_images_imf(image, imfs, genre_mapping, label, num_imfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed into FCN for feature extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed into SVM/Random Forest for classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
