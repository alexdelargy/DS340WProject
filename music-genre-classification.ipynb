{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scripts related to venv\n",
    "### Open a terminal\n",
    "- .venv\\Scripts\\activate\n",
    "- py -m pip install --upgrade pip\n",
    "- py -m pip install requests\n",
    "- py -m pip freeze > requirements.txt\n",
    "- py -m pip install -r requirements.txt\n",
    "\n",
    "# AWS Article\n",
    "- https://induraj2020.medium.com/how-to-access-the-s3-bucket-using-python-ecdbe5ebc45f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Classification\n",
    "In this notebook I tried to learn the basic concepts of neural networks and use it to classify the music files in dataset. Majorly this notebook can be divided into 3 parts:\n",
    "\n",
    "   1) Using ANN \n",
    "\n",
    "   2) Tackling overfitting with ANN\n",
    "\n",
    "   3) Using CNN\n",
    "\n",
    "\n",
    "Also to read the dataset I have used librosa library which only read files <1Mb and one file is greater than the size giving error due to which I have ignored it. The dataset contains the following genres, the keys being the prediction targets\n",
    "    \n",
    "    0: \"disco\",\n",
    "    1: \"metal\",\n",
    "    2: \"reggae\",\n",
    "    3: \"blues\",\n",
    "    4: \"rock\",\n",
    "    5: \"classical\",\n",
    "    6: \"jazz\",\n",
    "    7: \"hiphop\",\n",
    "    8: \"country\",\n",
    "    9: \"pop\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "01a50213-fe5d-431b-9ade-28c438b3bceb",
    "_uuid": "f32a1031-9332-42b6-8335-dee2b86310a3",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "from PIL import Image\n",
    "import boto3\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import numpy as np\n",
    "import warnings \n",
    "import requests\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(bucket_name, image_key, target_size=(128, 128)):\n",
    "    s3 = boto3.client('s3')\n",
    "    image_data = s3.get_object(Bucket=bucket_name, Key=image_key)['Body'].read()\n",
    "\n",
    "    image = Image.open(io.BytesIO(image_data)).convert('RGB')\n",
    "\n",
    "    image = image.resize(target_size)\n",
    "\n",
    "    return np.array(image).flatten() / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(bucket_name, dataset_path, target_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_mapping = {}\n",
    "    s3 = boto3.client('s3')\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "\n",
    "    for i, page in enumerate(paginator.paginate(Bucket=bucket_name, Prefix=dataset_path)):\n",
    "        if 'Contents' not in page:\n",
    "            continue\n",
    "        \n",
    "        for obj in page['Contents']:\n",
    "            image_key = obj['Key']\n",
    "            if image_key.endswith(\".png\"):\n",
    "                genre_label = image_key.split('/')[-2]\n",
    "\n",
    "                if genre_label not in label_mapping:\n",
    "                    label_mapping[genre_label] = len(label_mapping)\n",
    "\n",
    "                image_array = load_image(bucket_name, image_key, target_size)\n",
    "\n",
    "                images.append(image_array)\n",
    "                labels.append(label_mapping[genre_label])\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_images(bucket_name='flights12345', dataset_path=r\"Data/images_original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training/validation/testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "train_size = int(0.7 * 999)\n",
    "test_size = int(0.15 * 999)\n",
    "validation_size = int(0.15 * 999)\n",
    "\n",
    "groups = np.array([0] * train_size + [1] * test_size + [2] * validation_size)\n",
    "np.random.shuffle(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, validation_images, test_images = [], [], []\n",
    "train_labels, validation_labels, test_labels = np.array([]), np.array([]), np.array([])\n",
    "\n",
    "for i, group in enumerate(groups):\n",
    "    if group == 0:\n",
    "        train_images.append(images[i])\n",
    "        train_labels = np.append(train_labels, labels[i])\n",
    "    elif group == 1:\n",
    "        validation_images.append(images[i])\n",
    "        validation_labels = np.append(validation_labels, labels[i])\n",
    "    else:\n",
    "        test_images.append(images[i])\n",
    "        test_labels = np.append(test_labels, labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, validation_images, test_images = np.array(train_images), np.array(validation_images), np.array(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create IMFs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed into FCN for feature extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed into SVM/Random Forest for classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
